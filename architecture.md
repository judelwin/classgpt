# ğŸ§  ClassGPT Architecture

A scalable, modular Retrieval-Augmented Generation (RAG) system designed for multi-class academic document ingestion, semantic search, and LLM-based Q&A.

---

## ğŸ—‚ï¸ Project Structure

```bash
classgpt/
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ .env
â”œâ”€â”€ frontend/                     # React + Tailwind UI
â”‚   â”œâ”€â”€ public/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â”œâ”€â”€ api/                  # API wrapper functions
â”‚   â”‚   â”œâ”€â”€ context/              # Global state (e.g., user, class selection)
â”‚   â”‚   â””â”€â”€ App.tsx
â”‚   â””â”€â”€ package.json
â”œâ”€â”€ ingestion-service/           # PDF/slide parsing + OCR
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ parser.py
â”‚   â”œâ”€â”€ ocr.py
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ embedding-worker/            # Celery worker for embedding jobs
â”‚   â”œâ”€â”€ worker.py
â”‚   â”œâ”€â”€ embeddings.py
â”‚   â”œâ”€â”€ tasks.py
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ query-service/               # RAG pipeline + search endpoint
â”‚   â”œâ”€â”€ app.py
â”‚   â”œâ”€â”€ retriever.py
â”‚   â”œâ”€â”€ rag.py
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â””â”€â”€ query.py
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ vector-store/                # FAISS or Qdrant server (may be internal container or external DB)
â”‚   â””â”€â”€ (optional custom setup)
â”œâ”€â”€ api-gateway/                 # Optionally route between services
â”‚   â””â”€â”€ main.py
â”œâ”€â”€ shared/                      # Common logic used across services
â”‚   â”œâ”€â”€ chunking.py
â”‚   â”œâ”€â”€ utils.py
â”‚   â””â”€â”€ schema.py
â””â”€â”€ database/                    # PostgreSQL schema and migrations
    â”œâ”€â”€ init.sql
    â””â”€â”€ docker-entrypoint.sh
```

---

## ğŸ”„ Service Responsibilities

| Service            | Role                                                                 |
|--------------------|----------------------------------------------------------------------|
| `frontend`         | UI for uploading files, selecting classes, querying, and viewing responses |
| `ingestion-service`| Extracts text from PDFs, slides, and handwritten notes using OCR     |
| `embedding-worker` | Converts text chunks into embeddings and stores in vector DB         |
| `query-service`    | Handles RAG pipeline: top-k retrieval + LLM query + citation response |
| `vector-store`     | Stores and indexes embeddings (FAISS or Qdrant)                      |
| `database`         | Stores class metadata, document links, and job state                 |

---

## ğŸ§  Data Flow & State Management

### ğŸ“ Class-Based State
- Each user creates "classes" (e.g., CMSC351)
- Each class has its own document set and vector index namespace

### ğŸ“ Upload Pipeline
1. User uploads file to `/upload` (frontend â†’ ingestion-service)
2. `ingestion-service` parses + runs OCR (if needed)
3. Chunks are sent to `embedding-worker` via Redis/Celery
4. Embeddings are stored in `vector-store` (FAISS/Qdrant) under class ID
5. Metadata and status are recorded in PostgreSQL

### ğŸ” Query Pipeline
1. User enters question in UI for a specific class
2. Query sent to `query-service` with class ID
3. Top-k chunks are retrieved from `vector-store`
4. Chunks + query passed to LLM (OpenAI or local via LangChain)
5. LLM returns answer + source links
6. UI displays final response with inline citations

---

## ğŸ“¦ Docker Compose Configuration (`docker-compose.yml`)

```yaml
version: '3.9'

services:
  frontend:
    build: ./frontend
    ports:
      - "3000:3000"
    environment:
      - API_URL=http://localhost:8000

  ingestion-service:
    build: ./ingestion-service
    depends_on:
      - redis
    environment:
      - REDIS_URL=redis://redis:6379

  embedding-worker:
    build: ./embedding-worker
    depends_on:
      - redis
    environment:
      - REDIS_URL=redis://redis:6379

  query-service:
    build: ./query-service
    ports:
      - "8000:8000"
    depends_on:
      - vector-store
      - db

  vector-store:
    image: qdrant/qdrant
    ports:
      - "6333:6333"

  db:
    image: postgres
    ports:
      - "5432:5432"
    environment:
      POSTGRES_DB: classgpt
      POSTGRES_USER: user
      POSTGRES_PASSWORD: password

  redis:
    image: redis:alpine
```

---

## ğŸ—ƒï¸ PostgreSQL Database Schema (Simplified)

```sql
CREATE TABLE classes (
  id UUID PRIMARY KEY,
  user_id UUID,
  name TEXT
);

CREATE TABLE documents (
  id UUID PRIMARY KEY,
  class_id UUID REFERENCES classes(id),
  filename TEXT,
  status TEXT,
  uploaded_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE TABLE chunks (
  id UUID PRIMARY KEY,
  document_id UUID REFERENCES documents(id),
  chunk_index INT,
  content TEXT,
  embedding VECTOR(384) -- if stored outside FAISS/Qdrant
);
```

---

## ğŸ§± Component Stack

| Layer            | Tech Stack                        |
|------------------|------------------------------------|
| Frontend         | React, Tailwind, Axios, Context API |
| Backend APIs     | FastAPI or Flask                   |
| Workers          | Celery + Redis                     |
| Embeddings       | SentenceTransformers (MiniLM)      |
| Vector Store     | FAISS (local) or Qdrant (remote)   |
| LLM Integration  | OpenAI API or local (Ollama, HuggingFace) |
| OCR              | Tesseract / Google Cloud Vision    |
| Containerization | Docker, Docker Compose             |
| Deployment       | Vercel (frontend), Render/Fly.io (services) |

